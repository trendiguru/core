name: "VGG_ILSVRC_16_layers_vggbb"
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  python_param {
    module: "jrlayers"
    layer: "JrLayer"
    param_str: "{\'images_dir\': \'/home/jeremy/image_dbs/colorful_fashion_parsing_data/images/train_u21_256x256\', \'labels_dir\':\'/home/jeremy/image_dbs/colorful_fashion_parsing_data/labels_256x256/\',\'new_size\':(224,224), \'mean\': (104.00699, 116.66877, 122.67892)}"
  }
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  python_param {
    module: "jrlayers"
    layer: "JrLayer"
    param_str: "{\'images_dir\': \'/home/jeremy/image_dbs/colorful_fashion_parsing_data/images/test_u21_256x256\', \'labels_dir\':\'/home/jeremy/image_dbs/colorful_fashion_parsing_data/labels_256x256/\',\'new_size\':(224,224), \'mean\': (104.00699, 116.66877, 122.67892)}"
#    param_str: "{\'sbdd_dir\': \'../../data/sbdd/dataset\', \'seed\': 1337, \'split\': \'train\', \'mean\': (104.00699, 116.66877, 12$
  }
}
layer {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  name: "bn_conv1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  	batch_norm_param {
		use_global_stats: true
	}
}
layer {
  name: "scale1"
#  type: "ScaleLayer"
  type: "Scale"
  bottom: "bn1"
  top: "conv1_1"
  scale_param {bias_term: true}
}
#Further note: the BatchNorm layer only does the normalization! For the scale and shift also in the batch norm paper include a `ScaleLayer` with `scale_param { bias_term: true }`.
layer {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: "ReLU"
}

layer {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: "ReLU"
}

layer {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: "ReLU"
}
layer {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: "ReLU"
}
layer {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: "ReLU"
}
layer {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: "ReLU"
}
layer {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: "ReLU"
}
layer {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: "ReLU"
}
layer {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: "ReLU"
}
layer {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: "ReLU"
}
layer {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: "ReLU"
}
layer {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}

layer {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: "ReLU"
}
layer {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param{
    lr_mult: 1
    decay_mult: 1 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: "ReLU"
}
layer {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
####NEW LAYERS FROM HERE
layer {
  name: "myfc6"
  bottom: "pool5"
  top: "myfc6"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier" # initialize the filters from a Gaussian
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0.0  #this is what googlenet had
    }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  bottom: "myfc6"
  top: "myfc6"
  name: "relu6"
  type: "ReLU"
}
layer {
  bottom: "myfc6"
  top: "myfc6"
  name: "drop6"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "myfc7"
  bottom: "myfc6"
  top: "myfc7"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier" # initialize the filters from a Gaussian
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0.0  #this is what googlenet had
    }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  bottom: "myfc7"
  top: "myfc7"
  name: "relu7"
  type: "ReLU"
}
layer {
  bottom: "myfc7"
  top: "myfc7"
  name: "drop7"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "myfc8"
  bottom: "myfc7"
  top: "myfc8"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myrelu8"
  bottom: "myfc8"
  top: "myfc8"
  type: "ReLU"
}
layer {
  name: "dropout8"
  bottom: "myfc8"
  top: "myfc8"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.5
  }
}

#layer {
#  name: "myfc9"
#  bottom: "myfc8"
#  top: "myfc8"
#  type: "InnerProduct"
#  inner_product_param {
#    num_output: 4096
#  }
#  param{
#    lr_mult: 10
#    decay_mult: 10 }
#  param{
#    lr_mult: 20
#    decay_mult: 0 }
#}
#layer {
#  bottom: "myfc9"
#  top: "myfc9"
#  name: "myrelu9"
#  type: "ReLU"
#}
#layer {
#  name: "drop9"
#  bottom: "myfc9"
#  top: "myfc9"
#  type: "Dropout"
#  dropout_param {
#    dropout_ratio: 0.5
#  }
#}
#nn's has this as 256x4x4
layer{
  name: "reshape_8x8"
  type: "Reshape"
  bottom: "myfc8"
  top: "reshape_8x8"
  reshape_param {
    shape {
        dim: 0 #as the previous layer - can force to 1 if problematic  . -1 computes size to fit previous
	dim: 64
	dim: 8
	dim: 8 }
    }
}
layer {
  name: "myupconv5_3"
  bottom: "reshape_8x8"
  top: "myupconv5_3"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier" # initialize the filters from a Gaussian
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0.0  #this is what googlenet had
    }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu5_3"
  bottom: "myupconv5_3"
  top: "myupconv5_3"
  type: "ReLU"
}

layer {
  name: "myupconv5_2"
  bottom: "myupconv5_3"
  top: "myupconv5_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu5_2"
  bottom: "myupconv5_2"
  top: "myupconv5_2"
  type: "ReLU"
}

layer {
  name: "myupconv5_1"
  bottom: "myupconv5_2"
  top: "myupconv5_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0}
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu5_1"
  bottom: "myupconv5_1"
  top: "myupconv5_1"
  type: "ReLU"
}

layer {
  name: "deconv5"
  type: "Deconvolution"
  bottom: "myupconv5_1"
  top: "deconv5"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    pad:1
    num_output:512
    bias_term: true  #why set this false...originally false...
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "constant"
      value: 0.25 } # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0}
  }
}
layer {
  name: "deconv_relu5"
  bottom: "deconv5"
  top: "deconv5"
  type: "ReLU"
}

######### LAYER 4
layer {
  name: "myupconv4_3"
  bottom: "deconv5"
  top: "myupconv4_3"
  type: "Deconvolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "constant"
	value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  bottom: "myupconv4_3"
  top: "myupconv4_3"
  name: "myuprelu4_3"
  type: "ReLU"
}

layer {
  name: "myupconv4_2"
  bottom: "myupconv4_3"
  top: "myupconv4_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu4_2"
  bottom: "myupconv4_2"
  top: "myupconv4_2"
  type: "ReLU"
}

layer {
  name: "myupconv4_1"
  bottom: "myupconv4_2"
  top: "myupconv4_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu4_1"
  bottom: "myupconv4_1"
  top: "myupconv4_1"
  type: "ReLU"
}

layer {
  name: "deconv4"
  type: "Deconvolution"
  bottom: "myupconv4_1"
  top: "deconv4"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    pad:0
    num_output:512
    bias_term: true
    kernel_size: 2
    stride: 2
    weight_filler {
      type: "constant"
	value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
}


layer {
  name: "deconv4_relu"
  bottom: "deconv4"
  top: "deconv4"
  type: "ReLU"
}


######### LAYER 3
layer {
  name: "myupconv3_3"
  bottom: "deconv4"
  top: "myupconv3_3"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  bottom: "myupconv3_3"
  top: "myupconv3_3"
  name: "myuprelu3_3"
  type: "ReLU"
}

layer {
  name: "myupconv3_2"
  bottom: "myupconv3_3"
  top: "myupconv3_2"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu3_2"
  bottom: "myupconv3_2"
  top: "myupconv3_2"
  type: "ReLU"
}

layer {
  name: "myupconv3_1"
  bottom: "myupconv3_2"
  top: "myupconv3_1"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu3_1"
  bottom: "myupconv3_1"
  top: "myupconv3_1"
  type: "ReLU"
}

layer {
  name: "deconv3"
  type: "Deconvolution"
  bottom: "myupconv3_1"
  top: "deconv3"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    pad:1
    num_output:256
    bias_term: true
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "constant"
      value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
}
layer {
  name: "deconv_relu3"
  bottom: "deconv3"
  top: "deconv3"
  type: "ReLU"
}

######### LAYER 2
layer {
  name: "myupconv2_2"
  bottom: "deconv3"
  top: "myupconv2_2"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  bottom: "myupconv2_2"
  top: "myupconv2_2"
  name: "myuprelu2_2"
  type: "ReLU"
}

layer {
  name: "myupconv2_1"
  bottom: "myupconv2_2"
  top: "myupconv2_1"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu2_1"
  bottom: "myupconv2_1"
  top: "myupconv2_1"
  type: "ReLU"
}

layer {
  name: "deconv2"
  type: "Deconvolution"
  bottom: "myupconv2_1"
  top: "deconv2"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    pad:1
    num_output:128
    bias_term: true
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "constant"
	value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
}
layer {
  name: "deconv_relu2"
  bottom: "deconv2"
  top: "deconv2"
  type: "ReLU"
}


######### LAYER 1
layer {
  name: "myupconv1_2"
  bottom: "deconv2"
  top: "myupconv1_2"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "constant"
	value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  name: "myuprelu1_2"
  bottom: "myupconv1_2"
  top: "myupconv1_2"
  type: "ReLU"
}

layer {
  name: "myupconv1_1"
  bottom: "myupconv1_2"
  top: "myupconv1_1"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu1_1"
  bottom: "myupconv1_1"
  top: "myupconv1_1"
  type: "ReLU"
}

layer {
  name: "deconv1"
  type: "Deconvolution"
  bottom: "myupconv1_1"
  top: "deconv1"
  param {
    lr_mult: 10
    decay_mult: 10
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  convolution_param {
    pad:1
    num_output:64
    bias_term: true
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "constant"
	value: 0.25} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
}
layer {
  name: "deconv_relu1"
  bottom: "deconv1"
  top: "deconv1"
  type: "ReLU"
}

##############final conv layers
layer {
  name: "myupconv0_2"
  bottom: "deconv1"
  top: "myupconv0_2"
  type: "Convolution"
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 2
    decay_mult: 0 }
}
layer {
  name: "myuprelu0_2"
  bottom: "myupconv0_2"
  top: "myupconv0_2"
  type: "ReLU"
}

layer {
  name: "myupconv0_1"
  bottom: "myupconv0_2"
  top: "myupconv0_1"
  type: "Convolution"
  convolution_param {
    num_output: 21
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"} # initialize the filters from a Gaussian
    bias_filler {
      type: "constant" # initialize the filters from a Gaussian
	value: 0.0 }
  }
  param{
    lr_mult: 10
    decay_mult: 10 }
  param{
    lr_mult: 20
    decay_mult: 0 }
}
layer {
  name: "myuprelu0_1"
  bottom: "myupconv0_1"
  top: "myupconv0_1"
  type: "ReLU"
}


layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "myupconv0_1"
  bottom: "label"
  top: "loss"
  softmax_param {axis:1}
}


# layer {
#    name: "prob"
#    type: "Softmax"
#    bottom: "conv3"
#    top: "prob"
#    softmax_param { axis: 1 }
# }


layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "myupconv0_1"
  bottom: "label"
  top: "accuracy@1"
  include: { phase: TEST }
#  accuracy_param {
#    top_k: 1
#  }
}

#layer {
#  name: "accuracy/top5"
#  type: ACCURACY
# bottom: "fc8"
# bottom: "label"
#  top: "accuracy@5"
#  include: { phase: TEST }
#  accuracy_param {
#    top_k: 5
#  }
#}

